{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Embedding\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pdb import set_trace\n",
    "from lib import *\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id_fpath = 'data/word2id'\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "sentence_length = 32\n",
    "bert_hidden_size = 768\n",
    "learning_rate = 1e-3\n",
    "\n",
    "out_channels = 16\n",
    "kernel_weights = [2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.convs = []\n",
    "        for kernel_weight in kernel_weights:\n",
    "            conv = torch.nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=(kernel_weight, bert_hidden_size)\n",
    "            )\n",
    "            self.convs.append(conv)\n",
    "            setattr(self, 'conv-%d'%(kernel_weight), conv)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(\n",
    "            in_features=len(kernel_weights)*out_channels,\n",
    "            out_features=2\n",
    "        )\n",
    "        \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #set_trace()\n",
    "        segment_tensor = torch.zeros_like(X)\n",
    "        # 12, sentence_length, 768\n",
    "        encoder, _ = self.bert_model(X, segment_tensor)\n",
    "\n",
    "        last_layer = encoder[-1]\n",
    "        # for cnn (N, C, H, W) format, append in_channel in dim=1\n",
    "        last_layer = torch.unsqueeze(last_layer, 1)\n",
    "        #last_layer = self.dropout(last_layer)\n",
    "        \n",
    "        conv_outs = []\n",
    "        for conv in self.convs:\n",
    "            # batch_size, out_channels, sentence_length-kernel_weight+1, 1\n",
    "            conv_out = conv(last_layer)\n",
    "            # batch_size, out_channels, 1\n",
    "            # dim=2 is maxed out\n",
    "            conv_out, _ = torch.max(conv_out, dim=2)\n",
    "            \n",
    "            conv_outs.append(conv_out)\n",
    "\n",
    "        # batch_size, out_channels*len(kernel_weights), 1\n",
    "        conv_out = torch.cat(conv_outs, dim=1)\n",
    "        conv_out = torch.squeeze(conv_out)\n",
    "        # batch_size, out_channels*len(kernel_weights)\n",
    "        conv_out = conv_out.view(X.shape[0], -1)\n",
    "        \n",
    "        fc_out = self.fc1(conv_out)\n",
    "        logits = self.softmax(fc_out)\n",
    "        \n",
    "        return logits\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_dl(fpath, frac=0.00001):\n",
    "    dataset = QuoraInsinereQustion(fpath)\n",
    "    dataset.df = dataset.df.sample(frac=frac)\n",
    "    dl = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "train_dl = build_dl('data/train', frac=0.0001)\n",
    "val_dl = build_dl('data/val', frac=0.0001)\n",
    "\n",
    "model = CNN()\n",
    "#loss = CrossEntropyLoss()\n",
    "loss = CrossEntropyLoss(weight=torch.Tensor([1, 16]))\n",
    "trainable_tensors = [p[1] for p in model.named_parameters() if p[0].startswith('conv') or p[0].startswith('fc')]\n",
    "optimizer = Adam(params=trainable_tensors, lr=learning_rate)\n",
    "\n",
    "from ignite.engine import create_supervised_trainer, Events, create_supervised_evaluator\n",
    "from ignite.metrics import Loss, Accuracy, Precision, Recall\n",
    "trainer = create_supervised_trainer(model=model, optimizer=optimizer, loss_fn=loss)\n",
    "evaluator = create_supervised_evaluator(model=model, metrics={'Loss': Loss(loss), 'Accuracy': Accuracy(), 'Precision': Precision(), 'Recall': Recall()})\n",
    "metrics = Metrics()\n",
    "\n",
    "epoch_st = time()\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_loss(trainer):\n",
    "    evaluator.run(train_dl)\n",
    "    metrics.add_train(evaluator.state.metrics)\n",
    "\n",
    "    global epoch_st\n",
    "    elasped_time = int(time()-epoch_st)\n",
    "    epoch_st = time()\n",
    "\n",
    "    print(f\"epoch {trainer.state.epoch} {evaluator.state.metrics} {elasped_time}\")\n",
    "    evaluator.run(val_dl)\n",
    "    metrics.add_val(evaluator.state.metrics)\n",
    "    \n",
    "    plot_metrics(metrics)\n",
    "\n",
    "trainer.run(train_dl, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
